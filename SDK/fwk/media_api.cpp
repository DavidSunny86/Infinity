#include <al/al.h>
#include <al/alc.h>

extern "C"
{
#include <libavformat/avformat.h>
#include <libavcodec/avcodec.h>
#include <libavutil/opt.h>
#include <libswresample/swresample.h>
}

#include <gfx/gfx.h>

#define PACKET_BUFFER_SIZE    64

struct media_player_data_t
{
    AVFormatContext* formatContext;
    AVCodecContext*  audioContext;
    AVCodecContext*  videoContext;
    SwrContext*      resamplerContext;
    unsigned int     videoStream;
    unsigned int     audioStream;
    AVFrame*         pVFrame; 
    AVFrame*         pAFrame; 
    int              audioFormat;
    int              sampleRate;
    int              numBytes;
    int              width;
    int              height;
    PixelFormat      srcFormat;
    AVRational       frameDuration;
    int              playback;
    int              streamEnd;

    core::ring_buffer_t<AVPacket, PACKET_BUFFER_SIZE> aPackets;
    core::ring_buffer_t<AVPacket, PACKET_BUFFER_SIZE> vPackets;

    uint64_t baseTime, timeShift, timeOfNextFrame, frameTime;

    GLuint texY[2];
    GLuint texU[2];
    GLuint texV[2];

    ALuint  audioSource;
    ALuint  audioBuffers[2];


    int       aBufferSize;
    int       aBufferUsed;
    int       aSamplesCount;
    int       aSamplesUsed;
    uint8_t*  aBuffer;

    int subTasks;
    
    ALuint bufferToUpdate;

    uint32_t eventID;
    bool     taskStarted;
};

typedef struct media_player_data_t* media_player_t;

static int extAudioFormatsPresent;

GLuint progYUV2RGB;

static void closeAudioStream(media_player_t player);
static void closeVideoStream(media_player_t player);

static int openAudioStream(media_player_t player, AVCodecContext* audioContext)
{
    AVCodec* pAudioCodec;

    closeAudioStream(player);

    pAudioCodec=avcodec_find_decoder(audioContext->codec_id);
    if(pAudioCodec==NULL || avcodec_open2(audioContext, pAudioCodec, NULL)<0)
    {
        return 0;
    }

    player->audioContext = audioContext;

    //TODO: add support for multichannel audio if necessary
    player->audioFormat = AL_FORMAT_STEREO16;
    player->sampleRate  = 44100;

    int inLayout = (int)av_get_default_channel_layout(audioContext->channels);
    player->resamplerContext = swr_alloc_set_opts(
        NULL, AV_CH_LAYOUT_STEREO, AV_SAMPLE_FMT_S16, player->sampleRate,
        inLayout, audioContext->sample_fmt, audioContext->sample_rate,
        0, NULL
    );
    assert(player->resamplerContext);

    int ret = swr_init(player->resamplerContext);
    assert(ret>=0);

    player->aSamplesCount = 8192;
    player->aSamplesUsed  = 0;

    ret = av_samples_alloc(&player->aBuffer, &player->aBufferSize, 2, player->aSamplesCount, AV_SAMPLE_FMT_S16, 1);

    alGenSources(1, &player->audioSource);
    alGenBuffers(2, player->audioBuffers);

    return 1;
}

static void closeAudioStream(media_player_t player)
{
    if (player->audioContext)
    {
        avcodec_close(player->audioContext);
        swr_free(&player->resamplerContext);

        alSourceStop(player->audioSource);
        alDeleteBuffers(2, player->audioBuffers);
        alDeleteSources(1, &player->audioSource);

        player->audioContext     = 0;
        player->resamplerContext = 0;
        player->aBuffer          = 0;
    }
}

static void initTexture(GLuint tex, GLuint width, GLuint height)
{
    glTextureImage2DEXT(tex, GL_TEXTURE_2D, 0, GL_R8, width, height, 0, GL_RED, GL_UNSIGNED_BYTE, 0);
    glTextureParameteriEXT(tex, GL_TEXTURE_2D, GL_TEXTURE_MAX_LEVEL, 0);
    glTextureParameteriEXT(tex, GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
    glTextureParameteriEXT(tex, GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
    glTextureParameteriEXT(tex, GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
    glTextureParameteriEXT(tex, GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
}

static int openVideoStream(media_player_t player, AVCodecContext* videoContext)
{
    closeVideoStream(player);

    AVCodec* pVideoCodec=avcodec_find_decoder(videoContext->codec_id);
    if(pVideoCodec==NULL || avcodec_open2(videoContext, pVideoCodec, NULL)<0)
        return 0;

    // Hack to correct wrong frame rates that seem to be generated by some codecs
    // if(pVideoCodecCtx->frame_rate>1000 && pVideoCodecCtx->frame_rate_base==1)
    //    pVideoCodecCtx->frame_rate_base=1000;

    player->videoContext = videoContext;
    player->pVFrame      = av_frame_alloc();
    player->pAFrame      = av_frame_alloc();
    player->numBytes     = avpicture_get_size(PIX_FMT_YUV420P, videoContext->width, videoContext->height);

    player->width     = videoContext->width;
    player->height    = videoContext->height;
    player->srcFormat = videoContext->pix_fmt;
    assert(player->srcFormat == PIX_FMT_YUV420P);

    glGenTextures(2, player->texY);
    glGenTextures(2, player->texU);
    glGenTextures(2, player->texV);

    initTexture(player->texY[0], player->width,   player->height  );
    initTexture(player->texY[1], player->width,   player->height  );
    initTexture(player->texU[0], player->width/2, player->height/2);
    initTexture(player->texU[1], player->width/2, player->height/2);
    initTexture(player->texV[0], player->width/2, player->height/2);
    initTexture(player->texV[1], player->width/2, player->height/2);

    return 1;
}

static void closeVideoStream(media_player_t player)
{
    if (player->videoContext)
    {
        av_frame_free(&player->pVFrame);
        av_frame_free(&player->pAFrame);

        avcodec_close(player->videoContext);

        glDeleteTextures(2, player->texY);
        glDeleteTextures(2, player->texU);
        glDeleteTextures(2, player->texV);

        player->videoContext = 0;
    }
}

static void streamMediaData(media_player_t player)
{
    PROFILER_CPU_TIMESLICE("streamMediaData");

    AVPacket packet;

    if (!player->streamEnd && av_read_frame(player->formatContext, &packet)>=0)
    {
        if (packet.stream_index==player->audioStream)
        {
            *core::ring_buffer_alloc(player->aPackets) = packet;
        }
        else if (packet.stream_index==player->videoStream)
        {
            *core::ring_buffer_alloc(player->vPackets) = packet;
        }
    }
    else if (!player->streamEnd)
    {
        player->streamEnd = true;
        packet.data = 0;
        packet.size = 0;
        *core::ring_buffer_alloc(player->vPackets) = packet;
    }
}

static void decodeAudio(media_player_t player)
{
    PROFILER_CPU_TIMESLICE("decodeAudio");

    int audioDataAva;
    
    audioDataAva    = 1;
    player->aBufferUsed = 0;
    player->aSamplesUsed = 0;

    while((player->aSamplesUsed < player->aSamplesCount) && audioDataAva)
    {
        if (core::ring_buffer_used(player->aPackets)>0)
        {
            AVPacket* pkt       = core::ring_buffer_back(player->aPackets);
            int       frameDone = 0;

            avcodec_decode_audio4(player->audioContext, player->pAFrame, &frameDone, pkt);

            av_free_packet(pkt);
            core::ring_buffer_pop(player->aPackets);

            if(frameDone)
            {
                int srcRate = player->audioContext->sample_rate;
                int srcNSamples = player->pAFrame->nb_samples;
                int dstNSamples = (int)av_rescale_rnd(
                    swr_get_delay(player->resamplerContext, srcRate) + srcNSamples,
                    player->sampleRate, srcRate, AV_ROUND_UP);
                dstNSamples = core::min(dstNSamples, player->aSamplesCount-player->aSamplesUsed);

                uint8_t**  src = player->pAFrame->extended_data;
                uint8_t*   dst = player->aBuffer+player->aBufferUsed;
                dstNSamples = swr_convert(player->resamplerContext, &dst, dstNSamples, (const uint8_t**)src, srcNSamples);

                int bufSizeAva = dstNSamples*2/*channels*/*2/*sizeof(int16_t)*/; //NOTE: hardcode!!!
                assert(bufSizeAva>=0);

                player->aBufferUsed  += bufSizeAva;
                player->aSamplesUsed += dstNSamples;
            }
        }
        else
            streamMediaData(player);

        audioDataAva = !player->streamEnd || core::ring_buffer_used(player->aPackets)>0;
    }
}

static void decodeVideo(media_player_t player)
{
    PROFILER_CPU_TIMESLICE("decodeVideo");

    int videoDataAva = 1;

    while(videoDataAva)
    {
        if (core::ring_buffer_used(player->vPackets)>0)
        {
            AVPacket* pkt       = core::ring_buffer_back(player->vPackets);
            int       frameDone = 0;

            avcodec_decode_video2(player->videoContext, player->pVFrame, &frameDone, pkt);

            av_free_packet(pkt);
            core::ring_buffer_pop(player->vPackets);

            if(frameDone)
            {
                player->frameTime = player->frameDuration.num*pkt->dts*1000000/player->frameDuration.den;
                break;
            }
        }
        else
            streamMediaData(player);

        videoDataAva = !player->streamEnd || core::ring_buffer_used(player->vPackets)>0;
    }
}

static void uploadAudioData(media_player_t player, ALuint buffer)
{
    PROFILER_CPU_TIMESLICE("uploadAudioData");

    alBufferData(buffer, player->audioFormat, player->aBuffer, player->aBufferUsed, player->sampleRate);
    alSourceQueueBuffers(player->audioSource, 1, &buffer);
}

static void uploadVideoData(media_player_t player, GLuint texY, GLuint texU, GLuint texV)
{
    PROFILER_CPU_TIMESLICE("uploadVideoData");

    glPixelStorei(GL_UNPACK_ROW_LENGTH, player->pVFrame->linesize[0]);
    glTextureSubImage2DEXT(texY, GL_TEXTURE_2D, 0, 0, 0, player->width, player->height, GL_RED, GL_UNSIGNED_BYTE, player->pVFrame->data[0]);

    glPixelStorei(GL_UNPACK_ROW_LENGTH, player->pVFrame->linesize[1]);
    glTextureSubImage2DEXT(texU, GL_TEXTURE_2D, 0, 0, 0, player->width/2, player->height/2, GL_RED, GL_UNSIGNED_BYTE, player->pVFrame->data[1]);

    glPixelStorei(GL_UNPACK_ROW_LENGTH, player->pVFrame->linesize[2]);
    glTextureSubImage2DEXT(texV, GL_TEXTURE_2D, 0, 0, 0, player->width/2, player->height/2, GL_RED, GL_UNSIGNED_BYTE, player->pVFrame->data[2]);

    glPixelStorei(GL_UNPACK_ROW_LENGTH, 0);

    player->timeOfNextFrame = player->frameTime;
}

void mediaInit()
{
    // Register all formats and codecs
    av_register_all();

    const char* headers[] = {
        "#version 430\n",
        "#define ENABLE_TEXTURE\n",
        "#define ENABLE_COLOR\n"
    };

    progYUV2RGB = res::createProgramFromFiles("MESH.std.vert", "MEDIA.Texture.YUV.frag", ARRAY_SIZE(headers), headers);

    extAudioFormatsPresent = alIsExtensionPresent("AL_EXT_MCFORMATS");
}

void mediaShutdown()
{
    glDeleteProgram(progYUV2RGB);
}

media_player_t mediaCreatePlayer(const char* source)
{
    media_player_t player = (media_player_t)_aligned_malloc(sizeof(media_player_data_t), _alignof(media_player_data_t));

    mem_zero(player);

    if (avformat_open_input(&player->formatContext, source, NULL, 0)!=0)
        return 0;

    if (avformat_find_stream_info(player->formatContext, NULL)<0)
        return 0 ;

    av_dump_format(player->formatContext, 0, source, false); // Dump information about file onto standard error

    unsigned int  numStreams = player->formatContext->nb_streams;
    AVStream**    streams    = player->formatContext->streams;

    player->audioStream = numStreams;
    for(unsigned int i=0; i<numStreams; i++)
    {
        AVCodecContext* audioContext = streams[i]->codec;
        if(audioContext->codec_type==AVMEDIA_TYPE_AUDIO && openAudioStream(player, audioContext))
        {
            player->audioStream = i;
            break;
        }
    }

    player->videoStream = numStreams;
    for(unsigned int i=0; i<numStreams; i++)
    {
        AVCodecContext* videoContext = streams[i]->codec;
        if(streams[i]->codec->codec_type==AVMEDIA_TYPE_VIDEO && openVideoStream(player, videoContext))
        {
            player->videoStream   = i;
            player->frameDuration = streams[i]->time_base;
            break;
        }
    }

    player->taskStarted = false;
    player->eventID     = mt::INVALID_HANDLE;

    core::ring_buffer_reset(player->aPackets);
    core::ring_buffer_reset(player->vPackets);

    return player;
}

void mediaDestroyPlayer(media_player_t player)
{
    if (player->taskStarted)
    {
        mt::syncAndReleaseEvent(player->eventID);
    }

    core::ring_buffer_reset(player->aPackets);
    core::ring_buffer_reset(player->vPackets);

    closeAudioStream(player);
    closeVideoStream(player);

    avformat_close_input(&player->formatContext);
    _aligned_free(player);
}

enum 
{
    MEDIA_DECODE_VIDEO = 1,
    MEDIA_DECODE_AUDIO = 2,
};

static void doDecode(media_player_t player)
{
    PROFILER_CPU_TIMESLICE("mediaPlayerUpdateTask");

    if (player->subTasks&MEDIA_DECODE_VIDEO)
    {
        decodeVideo(player);
    }
    if (player->subTasks&MEDIA_DECODE_AUDIO)
    {
        decodeAudio(player);
    }
}

static void decodeTask(void* arg)
{
    media_player_t player = (media_player_t)arg;

    doDecode(player);
}

void mediaStartPlayback(media_player_t player)
{
    player->timeOfNextFrame = 0;
    player->streamEnd       = FALSE;

    player->subTasks = MEDIA_DECODE_VIDEO|MEDIA_DECODE_AUDIO;
    doDecode(player);
    uploadAudioData(player, player->audioBuffers[0]);
    uploadVideoData(player, player->texY[0], player->texU[0], player->texV[0]);
    player->timeShift = player->frameTime; //in some videos first dts differs from 0

    player->subTasks = MEDIA_DECODE_VIDEO|MEDIA_DECODE_AUDIO;
    doDecode(player);
    uploadAudioData(player, player->audioBuffers[1]);
    uploadVideoData(player, player->texY[1], player->texU[1], player->texV[1]);

    player->playback  = TRUE;
    player->baseTime  = timerAbsoluteTime();

    alSourcePlay(player->audioSource);
}

void mediaPlayerUpdate(media_player_t player)
{
    PROFILER_CPU_TIMESLICE("mediaPlayerUpdate");

    if (!player->playback)
        return;

    uint64_t currentTime = timerAbsoluteTime()-player->baseTime;

    ALuint buffer;

    player->playback = !player->streamEnd || core::ring_buffer_used(player->aPackets)>0 || core::ring_buffer_used(player->vPackets)>0;

    if (player->taskStarted)
    {
        mt::syncAndReleaseEvent(player->eventID);

        if (player->subTasks&MEDIA_DECODE_VIDEO)
        {
            uploadVideoData(player, player->texY[1], player->texU[1], player->texV[1]);
        }
        if (player->subTasks&MEDIA_DECODE_AUDIO)
        {
            uploadAudioData(player, player->bufferToUpdate);
        }
    }

    player->taskStarted = false;
    player->subTasks    = 0;

    {
        ALint  count;
        alGetSourcei(player->audioSource, AL_BUFFERS_PROCESSED, &count);
        if (count>0)
        {
            alSourceUnqueueBuffers(player->audioSource, 1, &buffer);
            player->subTasks |= MEDIA_DECODE_AUDIO;
            player->bufferToUpdate = buffer;
        }

        ALint state;
        alGetSourcei(player->audioSource, AL_SOURCE_STATE, &state);
        if (state != AL_PLAYING)
        {
            alSourcePlay(player->audioSource);
        }
    }

    uint64_t time = currentTime+player->timeShift;
    if (time>=player->timeOfNextFrame)
    {
        core::swap(player->texY[0], player->texY[1]);
        core::swap(player->texU[0], player->texU[1]);
        core::swap(player->texV[0], player->texV[1]);

        player->subTasks |= MEDIA_DECODE_VIDEO;
    }

    if (player->subTasks)
    {
        player->taskStarted = true;
        mt::addAsyncTask(decodeTask, player, &player->eventID);
    }
}

void mediaPlayerPrepareRender(media_player_t player)
{
    glUseProgram(progYUV2RGB);

    GLuint textures[] = {player->texY[0], player->texU[0], player->texV[0]};
    glBindTextures(0, ARRAY_SIZE(textures), textures);
}
