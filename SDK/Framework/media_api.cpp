#include <vector>
#include <cassert>

#include <opengl.h>
#include <al/al.h>
#include <al/alc.h>

extern "C"
{
#include <avformat.h>
#include <avcodec.h>
#include <swscale.h>
}

__int64 timerGetTimeMS();

#define NUM_BUFFERS 4

struct media_player_data_t
{

    AVFormatContext *pFormatCtx;
    AVCodecContext  *pVideoCodecCtx;
    AVCodecContext  *pAudioCodecCtx;
    SwsContext*		img_convert_ctx;
    unsigned int    videoStream;
    unsigned int    audioStream;
    AVFrame         *pFrame; 
    AVFrame         *pFrameRGB;
    int     		mAudioFormat;
    char*	        mAudioData;
    int             numBytes;
    int				width;
    int             height;
    uint8_t         *buffer;
    PixelFormat		srcFormat;
    PixelFormat     dstFormat;
    double			timeBase;
    int             playback;

    __int64 baseTime, timeOfNextFrame, curTexture, frameTime;

    //int					mAudioFormat;
    //std::vector<char>	mAudioData;
    //TODO: implement pool, maybe fixed at first!!!!
    GLuint texCur;
    GLuint texNext;
    ALuint		audioSource;
    ALuint		audioBuffers[NUM_BUFFERS];
    int			availableAudioBuffers;

    //TODO: implement pool, maybe fixed at first!!!!
    char __declspec(align(16)) audioBuf[AVCODEC_MAX_AUDIO_FRAME_SIZE];
    char __declspec(align(16)) audioBuf2[AVCODEC_MAX_AUDIO_FRAME_SIZE*10];
    int                               bufSize;
};

typedef struct media_player_data_t* media_player_t;


static int                        extAudioFormatsPresent;

//TODO: implement pool, maybe fixed at first!!!!
media_player_data_t               hack;

static void closeAudioStream(media_player_t player)
{
    if (player->pAudioCodecCtx)
    {
        avcodec_close(player->pAudioCodecCtx);

        ALint enqueuedBuffers;
        alGetSourcei(player->audioSource, AL_BUFFERS_QUEUED, &enqueuedBuffers);
        assert(player->availableAudioBuffers+enqueuedBuffers == NUM_BUFFERS);
        alSourceUnqueueBuffers(player->audioSource, enqueuedBuffers, player->audioBuffers+player->availableAudioBuffers);
        alDeleteSources(1, &player->audioSource);
        alDeleteBuffers(NUM_BUFFERS, player->audioBuffers);

        player->pAudioCodecCtx = 0;
    }
}

static int openAudioStream(media_player_t player, AVCodecContext* audioContext)
{
    AVCodec* pAudioCodec;
    int      channels;

    closeAudioStream(player);

    //FFMPEG always decodes to 16 PCM
    channels = audioContext->channels;
    if(channels == 1) player->mAudioFormat = AL_FORMAT_MONO16;
    else if(channels == 2) player->mAudioFormat = AL_FORMAT_STEREO16;
    else if(extAudioFormatsPresent && channels == 4) player->mAudioFormat = alGetEnumValue("AL_FORMAT_QUAD16");
    else if(extAudioFormatsPresent && channels == 6) player->mAudioFormat = alGetEnumValue("AL_FORMAT_51CHN16");
    else
    {
        //TODO: encode in AL_FORMAT_STEREO16
        return 0;
    }

    pAudioCodec=avcodec_find_decoder(audioContext->codec_id);
    if(pAudioCodec==NULL || avcodec_open(audioContext, pAudioCodec)<0)
    {
        return 0;
    }

    player->pAudioCodecCtx = audioContext;

	alGenSources(1, &player->audioSource);
	alGenBuffers(NUM_BUFFERS, player->audioBuffers);

    player->availableAudioBuffers = NUM_BUFFERS;

    return 1;
}

static void closeVideoStream(media_player_t player)
{
    if (player->pVideoCodecCtx)
    {
        sws_freeContext(player->img_convert_ctx);

        free(player->buffer);
        av_free(player->pFrameRGB);
        av_free(player->pFrame);

        avcodec_close(player->pVideoCodecCtx);

        glDeleteTextures(1, &player->texCur);
        glDeleteTextures(1, &player->texNext);

        player->pVideoCodecCtx = 0;
        player->bufSize = 0;
    }
}

static int openVideoStream(media_player_t player, AVCodecContext* videoContext)
{
    closeVideoStream(player);

    AVCodec* pVideoCodec=avcodec_find_decoder(videoContext->codec_id);
    if(pVideoCodec==NULL || avcodec_open(videoContext, pVideoCodec)<0)
        return 0; // Could not open codec

    // Hack to correct wrong frame rates that seem to be generated by some codecs
    // if(pVideoCodecCtx->frame_rate>1000 && pVideoCodecCtx->frame_rate_base==1)
    //    pVideoCodecCtx->frame_rate_base=1000;

    player->pVideoCodecCtx = videoContext;

    player->pFrame    = avcodec_alloc_frame();
    player->pFrameRGB = avcodec_alloc_frame();

    player->numBytes = avpicture_get_size(PIX_FMT_RGB24, videoContext->width, videoContext->height);
    player->buffer   = (uint8_t*)malloc(player->numBytes);

    // Assign appropriate parts of buffer to image planes in pFrameRGB
    avpicture_fill((AVPicture *)player->pFrameRGB, player->buffer, PIX_FMT_RGB24, videoContext->width, videoContext->height);

    player->width     = videoContext->width;
    player->height    = videoContext->height;
    player->srcFormat = videoContext->pix_fmt;
    player->dstFormat = PIX_FMT_RGB24;
    player->img_convert_ctx = sws_getContext(
        player->width, player->height, player->srcFormat, 
        player->width, player->height, player->dstFormat,
        SWS_BICUBIC, NULL, NULL, NULL
    );

    glGenTextures(1, &player->texCur);
    glGenTextures(1, &player->texNext);

    glBindTexture(GL_TEXTURE_2D, player->texCur);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAX_LEVEL, 0);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);

    glBindTexture(GL_TEXTURE_2D, player->texNext);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAX_LEVEL, 0);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);

    return 1;
}

static void decodeFrame(media_player_t player, GLuint texture, ALuint buffer)
{
    AVPacket        packet;
    int             frameCompleted;
        
    frameCompleted = 0;
    while(player->playback = (av_read_frame(player->pFormatCtx, &packet)>=0))
    {
        if (packet.stream_index==player->audioStream)
        {
            uint8_t*	inData     = packet.data;
            int			inSize     = packet.size;
            int         bufSizeAva = AVCODEC_MAX_AUDIO_FRAME_SIZE;

            while(inSize > 0)
            {
                int processed = avcodec_decode_audio2(player->pAudioCodecCtx, (int16_t*)player->audioBuf, &bufSizeAva, inData, inSize);

                if(processed < 0)
                {
                    break;
                }

                inData     += processed;
                inSize     -= processed;

                if (processed>0)
                {
                    assert(player->bufSize+bufSizeAva<AVCODEC_MAX_AUDIO_FRAME_SIZE*10);
                    memcpy(player->audioBuf2+player->bufSize, player->audioBuf, bufSizeAva);
                    player->bufSize += bufSizeAva;
                }
            }
            av_free_packet(&packet);
        }
        if (packet.stream_index==player->videoStream)
        {
            avcodec_decode_video(player->pVideoCodecCtx, player->pFrame, &frameCompleted, packet.data, packet.size);

            if(frameCompleted)
            {
                player->timeOfNextFrame = player->baseTime+player->timeBase*packet.dts*1000;
                av_free_packet(&packet);
                break;
            }
        }

        //Free the packet that was allocated by av_read_frame
        av_free_packet(&packet);
    }

    int realWidth = player->pFrameRGB->linesize[0];

    sws_scale(player->img_convert_ctx, player->pFrame->data, player->pFrame->linesize, 0, 
        player->height, player->pFrameRGB->data, player->pFrameRGB->linesize);

    glBindTexture(GL_TEXTURE_2D, texture);
    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA8, player->width, player->height, 0, GL_RGB, GL_UNSIGNED_BYTE, 0);
    for(GLsizei y=0; y<player->height; y++)
    {
        glTexSubImage2D(GL_TEXTURE_2D, 0, 0, y, player->width, 1, GL_RGB, GL_UNSIGNED_BYTE,
            player->pFrameRGB->data[0]+y*realWidth);
        GLenum err = glGetError();
        assert(err == GL_NO_ERROR);
    }

    glBindTexture(GL_TEXTURE_2D, 0);

    if (player->bufSize>0 && player->availableAudioBuffers>0)
    {
        ALuint buffer = player->audioBuffers[--player->availableAudioBuffers];
        alBufferData(buffer, player->mAudioFormat, player->audioBuf2, player->bufSize, player->pAudioCodecCtx->sample_rate);
        alSourceQueueBuffers(player->audioSource, 1, &buffer);
        player->bufSize = 0;
    }

    ALint state;
    alGetSourcei(player->audioSource, AL_SOURCE_STATE, &state);
    if (state != AL_PLAYING)
    {
        alSourcePlay(player->audioSource);
    }
}

void mediaInit()
{
    // Register all formats and codecs
    av_register_all();

    extAudioFormatsPresent = alIsExtensionPresent("AL_EXT_MCFORMATS");
}

void mediaShutdown()
{
}

media_player_t mediaCreatePlayer(const char* source)
{
    media_player_t player = &hack;

    if (av_open_input_file(&player->pFormatCtx, source, NULL, 0, NULL)!=0)
        return 0;

    if (av_find_stream_info(player->pFormatCtx)<0)
        return 0 ;

    // Dump information about file onto standard error
    dump_format(player->pFormatCtx, 0, source, false);

    unsigned int  numStreams = player->pFormatCtx->nb_streams;
    AVStream**    streams    = player->pFormatCtx->streams;

    player->audioStream = numStreams;
    for(unsigned int i=0; i<numStreams; i++)
    {
        AVCodecContext* audioContext = streams[i]->codec;
        if(audioContext->codec_type==CODEC_TYPE_AUDIO && openAudioStream(player, audioContext))
        {
            player->audioStream = i;
            break;
        }
    }

    player->videoStream = numStreams;
    for(unsigned int i=0; i<numStreams; i++)
    {
        AVCodecContext* videoContext = streams[i]->codec;
        if(streams[i]->codec->codec_type==CODEC_TYPE_VIDEO && openVideoStream(player, videoContext))
        {
            player->videoStream = i;
            player->timeBase  = av_q2d(streams[i]->time_base);
            break;
        }
    }

    return player;
}

void mediaDestroyPlayer(media_player_t player)
{
    closeAudioStream(player);
    closeVideoStream(player);

    av_close_input_file(player->pFormatCtx);
}

void mediaStartPlayback(media_player_t player)
{
    player->playback = TRUE;
    player->timeOfNextFrame = player->baseTime = timerGetTimeMS();
    decodeFrame(player, player->texNext, 0);
}

void mediaPlayerUpdate(media_player_t player)
{
    //AVPacket        packet;
    //int frameFinished = 0;

    if (!player->playback)
        return;

    if (timerGetTimeMS()>=player->timeOfNextFrame)
    {
        std::swap(player->texCur, player->texNext);

        ALint  count;
        alGetSourcei(player->audioSource, AL_BUFFERS_PROCESSED, &count);
        if (count>0)
        {
            ALuint buffer;
        	alSourceUnqueueBuffers(player->audioSource, 1, &buffer);
            //enqueue buffer to free list
            assert(player->availableAudioBuffers<NUM_BUFFERS);
            player->audioBuffers[player->availableAudioBuffers++] = buffer;
        }

        decodeFrame(player, player->texNext, 0);
    }
}

void mediaPlayerRender(media_player_t player)
{
    const GLfloat w = 6.4f*1.1f, h = 3.6f*1.1f;

    glMatrixMode(GL_MODELVIEW);
    glLoadIdentity();
    glTranslatef(0, 0, -5);

    glBindTexture(GL_TEXTURE_2D, player->texCur);
    glEnable(GL_TEXTURE_2D);
    glColor3f(1, 1, 1);
    glBegin(GL_QUADS);
    glTexCoord2f(0, 0);
    glVertex2f(-w/2,  h/2);
    glTexCoord2f(1, 0);
    glVertex2f( w/2,  h/2);
    glTexCoord2f(1, 1);
    glVertex2f( w/2, -h/2);
    glTexCoord2f(0, 1);
    glVertex2f(-w/2, -h/2);
    glEnd();
}